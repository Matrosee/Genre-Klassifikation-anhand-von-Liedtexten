{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matrosee/Genre-Klassifikation-anhand-von-Liedtexten/blob/main/Code_von_Jannic_M_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyb6mPpCJADk"
      },
      "source": [
        "# Installationen, Imports und Downloads:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installationen:"
      ],
      "metadata": {
        "id": "gdh2wodVNzZE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKornHEzn-PV"
      },
      "outputs": [],
      "source": [
        "!pip install lightgbm\n",
        "!pip install spacy\n",
        "!pip install scikit-learn\n",
        "!pip install numpy\n",
        "!python -m spacy download en_core_web_md\n",
        "!pip install scikit-learn\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install flaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ],
      "metadata": {
        "id": "tPehy4oEN208"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "N0HqVeIzJJrR"
      },
      "outputs": [],
      "source": [
        "import flaml\n",
        "import lightgbm as lgb\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "from flaml import AutoML\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMClassifier\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads:"
      ],
      "metadata": {
        "id": "I7cRPYzKN4tt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACQnvRGSR2uc"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D48vtzWGJAxi"
      },
      "source": [
        "# Upload & Dataframe Deklaration:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlVoFF0ynk6D",
        "outputId": "936e95d9-200e-4f44-fcd4-78eecf705f9a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/train.csv')"
      ],
      "metadata": {
        "id": "6zqKSYp3Be9l"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/gdrive/MyDrive/test.csv')"
      ],
      "metadata": {
        "id": "dCMkjgqaEDOy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRr671g-UD2w"
      },
      "source": [
        "# 1890 Songs-pro-Datensatz erstellen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wtUibkdaUD2w"
      },
      "outputs": [],
      "source": [
        "# Nur Englische-Lieder einstellen\n",
        "df = df.loc[df['Language']=='en']\n",
        "\n",
        "# Pro Genre ein eigenes Dataframe mit je 1890 Liedern\n",
        "df_rock_one = df[df['Genre']=='Rock']\n",
        "df_rock_one = df_rock_one.head(1890)\n",
        "\n",
        "df_pop_one = df[df['Genre']=='Pop']\n",
        "df_pop_one = df_pop_one.head(1890)\n",
        "\n",
        "df_metal_one = df[df['Genre']=='Metal']\n",
        "df_metal_one = df_metal_one.head(1890)\n",
        "\n",
        "df_hip_hop_one = df[df['Genre']=='Hip-Hop']\n",
        "df_hip_hop_one = df_hip_hop_one.head(1890)\n",
        "\n",
        "df_rnb_one = df[df['Genre']=='R&B']\n",
        "df_rnb_one = df_rnb_one.head(1890)\n",
        "\n",
        "df_indie_one = df[df['Genre']=='Indie']\n",
        "df_indie_one = df_indie_one.head(1890)\n",
        "\n",
        "df_electronic_one = df[df['Genre']=='Electronic']\n",
        "df_electronic_one = df_electronic_one.head(1890)\n",
        "\n",
        "df_jazz_one = df[df['Genre']=='Jazz']\n",
        "df_jazz_one = df_jazz_one.head(1890)\n",
        "\n",
        "df_folk_one = df[df['Genre']=='Folk']\n",
        "df_folk_one = df_folk_one.head(1890)\n",
        "\n",
        "df_country_one = df[df['Genre']=='Country']\n",
        "df_country_one = df_country_one.head(1890)\n",
        "\n",
        "# Alle einzelnen Dataframes zu einem zusammfügen\n",
        "df_one = pd.concat([df_pop_one, df_hip_hop_one, df_metal_one, df_rock_one, \n",
        "                    df_indie_one, df_country_one, df_electronic_one, df_rnb_one,\n",
        "                    df_jazz_one, df_folk_one])\n",
        "\n",
        "# Kürzeren Namen für zuküftige Arbeit auswählen\n",
        "df = df_one\n",
        "\n",
        "# Spalten ohne Beiträge löschen \n",
        "df.dropna()\n",
        "\n",
        "# Index reseten\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hbI7RZuVHsq"
      },
      "source": [
        "# Pre-Processing:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(axis=1)"
      ],
      "metadata": {
        "id": "ZEN8vKbOrymD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "krrAcvz7VHsq"
      },
      "outputs": [],
      "source": [
        "# Laden Sie das spacy-Modell und den Englisch-Vokabular\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Stop-Wörter auf einer Variable deklarieren\n",
        "en_stops = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGWeBqPjVHsr"
      },
      "source": [
        "Datensatz säubern:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "f8R7uEVeVHsr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "38afa97a-ecf7-49a4-c660-cb0f88a8720f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Genre                                             Lyrics  \\\n",
              "0       Pop  Twenty-five years and my life is still\\nTrying...   \n",
              "1       Pop  Starry night bring me down\\nTill I realize the...   \n",
              "2       Pop  Every time you wake in the mornin'\\nAnd you st...   \n",
              "3       Pop  What ya gonna do child\\nWhen your thoughts are...   \n",
              "4       Pop  How can you tell, when your wellness is not we...   \n",
              "...     ...                                                ...   \n",
              "18895  Folk  One for the money and two for the show\\nThree ...   \n",
              "18896  Folk  Carmilla are you still there-ere, I heard you ...   \n",
              "18897  Folk  Oh Jo-osephine, well you won't fi-ind your dre...   \n",
              "18898  Folk  I've got my li-ife, you've got your li-ife\\nWe...   \n",
              "18899  Folk  The Colorado Ballroom is alive tonight\\nMasked...   \n",
              "\n",
              "                                          cleaned_lyrics  \n",
              "0      Twenty-five years and my life is still Trying ...  \n",
              "1      Starry night bring me down Till I realize the ...  \n",
              "2      Every time you wake in the mornin' And you sta...  \n",
              "3      What ya gonna do child When your thoughts are ...  \n",
              "4      How can you tell, when your wellness is not we...  \n",
              "...                                                  ...  \n",
              "18895  One for the money and two for the show Three f...  \n",
              "18896  Carmilla are you still there-ere, I heard you ...  \n",
              "18897  Oh Jo-osephine, well you won't fi-ind your dre...  \n",
              "18898  I've got my li-ife, you've got your li-ife We ...  \n",
              "18899  The Colorado Ballroom is alive tonight Masked ...  \n",
              "\n",
              "[18900 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcddf43a-b006-421d-baad-c8d89de8d625\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Genre</th>\n",
              "      <th>Lyrics</th>\n",
              "      <th>cleaned_lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Twenty-five years and my life is still\\nTrying...</td>\n",
              "      <td>Twenty-five years and my life is still Trying ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Starry night bring me down\\nTill I realize the...</td>\n",
              "      <td>Starry night bring me down Till I realize the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Every time you wake in the mornin'\\nAnd you st...</td>\n",
              "      <td>Every time you wake in the mornin' And you sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pop</td>\n",
              "      <td>What ya gonna do child\\nWhen your thoughts are...</td>\n",
              "      <td>What ya gonna do child When your thoughts are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pop</td>\n",
              "      <td>How can you tell, when your wellness is not we...</td>\n",
              "      <td>How can you tell, when your wellness is not we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18895</th>\n",
              "      <td>Folk</td>\n",
              "      <td>One for the money and two for the show\\nThree ...</td>\n",
              "      <td>One for the money and two for the show Three f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18896</th>\n",
              "      <td>Folk</td>\n",
              "      <td>Carmilla are you still there-ere, I heard you ...</td>\n",
              "      <td>Carmilla are you still there-ere, I heard you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18897</th>\n",
              "      <td>Folk</td>\n",
              "      <td>Oh Jo-osephine, well you won't fi-ind your dre...</td>\n",
              "      <td>Oh Jo-osephine, well you won't fi-ind your dre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18898</th>\n",
              "      <td>Folk</td>\n",
              "      <td>I've got my li-ife, you've got your li-ife\\nWe...</td>\n",
              "      <td>I've got my li-ife, you've got your li-ife We ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18899</th>\n",
              "      <td>Folk</td>\n",
              "      <td>The Colorado Ballroom is alive tonight\\nMasked...</td>\n",
              "      <td>The Colorado Ballroom is alive tonight Masked ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18900 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcddf43a-b006-421d-baad-c8d89de8d625')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dcddf43a-b006-421d-baad-c8d89de8d625 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dcddf43a-b006-421d-baad-c8d89de8d625');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Sonderzeichen entfernen\n",
        "df['Lyrics'] = [re.sub(r'^.*?Lyrics', '', str(lyric)) for lyric in df['Lyrics']]\n",
        "\n",
        "# Satzumbruch Zeichen entfernen\n",
        "df['cleaned_lyrics'] = [str(lyric).replace('\\n',' ') for lyric in df['Lyrics']]\n",
        "\n",
        "# Wörter in eckigen Klammern entfernen\n",
        "df['cleaned_lyrics'] = [re.sub(\"\\[.*?\\]\",\"\",lyric) for lyric in df['cleaned_lyrics']]\n",
        "\n",
        "# Language-, Song-Name- und Artist-Spalte löschen\n",
        "df = df.drop('Language',axis=1)\n",
        "df = df.drop('Song', axis=1)\n",
        "df = df.drop('Artist', axis=1)\n",
        "\n",
        "# Den Index resetten\n",
        "df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJe5rcJqVHsr"
      },
      "source": [
        "Stemming:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "530_7fz4VHsr"
      },
      "outputs": [],
      "source": [
        "# Neue Spalte erstellen und die Liedtexte ohne Endungen in die Spalte speichen\n",
        "df['stemmed_lyrics'] = \"\"\n",
        "ps = PorterStemmer() \n",
        "space = \" \"\n",
        "tmp = \"\"\n",
        "count = 0\n",
        "for lyric in df['cleaned_lyrics']:\n",
        "  words = word_tokenize(lyric)\n",
        "  tmp = \"\"\n",
        "  for word in words:\n",
        "    tmp = tmp + space + ps.stem(word)\n",
        "  df['stemmed_lyrics'].iloc[count] = tmp\n",
        "  count = count + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7SJ5PlDVHsr"
      },
      "source": [
        "Stop-Words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "liu4uNZSVHsr"
      },
      "outputs": [],
      "source": [
        "# Neue Spalte erstellen und die Liedtexte ohne Stoppwörter in die Spalte speichen\n",
        "df['wosw_lyrics'] = \"\"\n",
        "space = \" \"\n",
        "tmp = \"\"\n",
        "count = 0\n",
        "for lyric in df['cleaned_lyrics']:\n",
        "  words = word_tokenize(lyric)\n",
        "  tmp = \"\"\n",
        "  for word in words:\n",
        "    if word not in en_stops:\n",
        "      tmp = tmp + space + word\n",
        "  df['wosw_lyrics'].iloc[count] = tmp\n",
        "  count = count + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxB1Yp0xVHsr"
      },
      "source": [
        "Stemming -> Stop-Words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yl263qPuVHss"
      },
      "outputs": [],
      "source": [
        "# Neue Spalte erstellen und die Liedtexte ohne Endungen und ohne Stoppwörter in die Spalte speichen\n",
        "df['stemmed_wosw_lyrics'] = \"\"\n",
        "space = \" \"\n",
        "tmp = \"\"\n",
        "count = 0\n",
        "for lyric in df['stemmed_lyrics']:\n",
        "  words = word_tokenize(lyric)\n",
        "  tmp = \"\"\n",
        "  for word in words:\n",
        "    if word not in en_stops:\n",
        "      tmp = tmp + space + word\n",
        "  df['stemmed_wosw_lyrics'].iloc[count] = tmp\n",
        "  count = count + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98giNuxoVHss"
      },
      "source": [
        "StopWords -> Stemming:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "TLEpCAkrVHss"
      },
      "outputs": [],
      "source": [
        "# Neue Spalte erstellen und die Liedtexte ohne Stoppwörter und ohne Endungen in die Spalte speichen\n",
        "df['wosw_stemmed_lyrics'] = \"\"\n",
        "ps = PorterStemmer() \n",
        "space = \" \"\n",
        "tmp = \"\"\n",
        "count = 0\n",
        "for lyric in df['wosw_lyrics']:\n",
        "  words = word_tokenize(lyric)\n",
        "  tmp = \"\"\n",
        "  for x in words:\n",
        "    tmp = tmp + space + ps.stem(x)\n",
        "  df['wosw_stemmed_lyrics'].iloc[count] = tmp\n",
        "  count = count + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRpm6PPNA00O"
      },
      "source": [
        "# Einstellen, welche Lyrik-Spalten verwendet werden sollen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zQd0Ei6EBBk6"
      },
      "outputs": [],
      "source": [
        "# Laden Sie die Textdokumente und die Klassenlabels\n",
        "df_train_lyrics = df['Lyrics'].tolist() # Dataframe mit Textdokumenten\n",
        "df_train_labels = df['Genre'] # Dataframe mit Klassenlabels (eins pro Dokument)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Laden Sie die Textdokumente und die Klassenlabels\n",
        "df_test_lyrics = df_test['Lyrics'] # Dataframe mit Textdokumenten\n",
        "df_test_labels = df_test['Genre'] # Dataframe mit Klassenlabels (eins pro Dokument)"
      ],
      "metadata": {
        "id": "VlMGVo92Qttx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhYo2eIkBcec"
      },
      "source": [
        "# Grid-search SVM mit SKLEARN:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1trYSBced"
      },
      "source": [
        "Wie ich die optimalen Paramter rausfinde?\n",
        "Ich gebe grobe Werte für die Paramter an und werde immer genauer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brKfkJobBced"
      },
      "source": [
        "CountVektorizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKwP4Lo2jx5R"
      },
      "outputs": [],
      "source": [
        "# Konvertieren Sie die Textdokumente in numerische Merkmale mit dem CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df_train_lyrics)\n",
        "\n",
        "# Teilen Sie die Daten in Trainings- und Testdaten auf\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df_train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Erstellen Sie ein SVM-Modell\n",
        "svm = SVC()\n",
        "\n",
        "# Definieren Sie die Hyperparameter, die Sie durchsuchen möchten\n",
        "# Definieren Sie die Hyperparameter, die Sie durchsuchen möchten\n",
        "param_grid_svm = {'C': [0.011, 0.012, 0.014], \n",
        "                  'gamma': [0.075, 0.079, 0.0795],\n",
        "                  'kernel': ['linear']}\n",
        "\n",
        "# Erstelle eine GridSearchCV-Instanz \n",
        "grid_svm = GridSearchCV(svm, param_grid_svm, refit = True, verbose = 3)\n",
        "\n",
        "# Trainiere dein Modell mit der GridSearchCV\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "# Auswähle den besten Parameter\n",
        "best_params_svm = grid_svm.best_params_\n",
        "\n",
        "# Die besten Parameter ausgeben\n",
        "print(best_params_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KYBnEosBced"
      },
      "source": [
        "SVM mit TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkIa0_r4Bcee"
      },
      "outputs": [],
      "source": [
        "# Konvertieren Sie die Textdokumente in numerische Merkmale mit dem TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df_train_lyrics)\n",
        "\n",
        "# Teilen Sie die Daten in Trainings- und Testdaten auf\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df_train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Erstellen Sie ein SVM-Modell\n",
        "svm = SVC()\n",
        "\n",
        "# Definieren Sie die Hyperparameter, die Sie durchsuchen möchten\n",
        "# Definieren Sie die Hyperparameter, die Sie durchsuchen möchten\n",
        "param_grid_svm = {'C': [4.5], \n",
        "                  'gamma': [0.95,1,3,5,10],\n",
        "                  'kernel': ['rbf']}\n",
        "\n",
        "# Erstelle eine GridSearchCV-Instanz \n",
        "grid_svm = GridSearchCV(svm, param_grid_svm, refit = True, verbose = 3)\n",
        "\n",
        "# Trainiere dein Modell mit der GridSearchCV\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "# Auswähle den besten Parameter\n",
        "best_params_svm = grid_svm.best_params_\n",
        "\n",
        "# Die besten Parameter ausgeben\n",
        "print(best_params_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npjNFl0tBcee"
      },
      "source": [
        "Spacy:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Funktion definieren, um die Liedtexte in Vektoren zu konvertieren\n",
        "# def document_vector(text):\n",
        "#     doc = nlp(text)\n",
        "#     vectors = []\n",
        "#     for token in doc:\n",
        "#         if token.has_vector:\n",
        "#             vectors.append(token.vector)\n",
        "#     if len(vectors) > 0:\n",
        "#         return np.mean(vectors, axis=0)\n",
        "#     else:\n",
        "#         raise ValueError(\"Keine Vektoren gefunden\")\n",
        "\n",
        "# # Herausfinden, in welchen Spalten keine Vektoren vorhanden sind\n",
        "# no_vector_docs = []\n",
        "# for i, text in enumerate(df_train_lyrics):\n",
        "#     try:\n",
        "#         vec = document_vector(text)\n",
        "#     except ValueError as e:\n",
        "#         print(f\"Fehler: {e} bei Dokument {i}\")\n",
        "#         no_vector_docs.append(i)\n",
        "# print(f\"Dokumente ohne Vektoren: {no_vector_docs}\")\n",
        "\n",
        "# # Alle Zeilen ohne Vektoren löschen\n",
        "# for i in no_vector_docs:\n",
        "#   df_train_labels = df_train_labels.drop(i)\n",
        "#   del df_train_lyrics[i]\n",
        "\n",
        "# # Das Dataframe für die Labels reindexen\n",
        "# df_train_labels = df_train_labels.reset_index(drop=True)  \n",
        "\n",
        "# # Compute the document vectors\n",
        "# documents_with_vectors = []\n",
        "# labels_with_vectors = []\n",
        "# for i in range(len(df_train_lyrics)):\n",
        "#     text = df_train_lyricss[i]\n",
        "#     df_train_labels = df_train_labels[i]\n",
        "#     try:\n",
        "#         vec = document_vector(text)\n",
        "#         documents_with_vectors.append(text)\n",
        "#         labels_with_vectors.append(label)\n",
        "#     except ValueError as e:\n",
        "#         print(f\"Fehler: {e}\")\n",
        "\n",
        "# # Compute the document vectors\n",
        "# X = [document_vector(text) for text in documents_with_vectors]\n",
        "\n",
        "# # Teilen Sie die Daten in Trainings- und Testdaten auf\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, labels_with_vectors, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Erstellen Sie ein SVM-Modell\n",
        "# svm = SVC()\n",
        "\n",
        "# # Definieren Sie die Hyperparameter, die Sie durchsuchen möchten\n",
        "# param_grid_svm = {'C': [1, 5], \n",
        "#                   'gamma': [10, 1, 0.1],\n",
        "#                   'kernel': ['linear']}\n",
        "\n",
        "# # Erstelle eine GridSearchCV-Instanz \n",
        "# grid_svm = GridSearchCV(svm, param_grid_svm, refit = True, verbose = 3)\n",
        "\n",
        "# # Trainiere dein Modell mit der GridSearchCV\n",
        "# grid_svm.fit(X_train, y_train)\n",
        "\n",
        "# # Auswähle den besten Parameter\n",
        "# best_params_svm = grid_svm.best_params_\n",
        "\n",
        "# # Die besten Parameter ausgeben\n",
        "# print(best_params_svm)"
      ],
      "metadata": {
        "id": "g_3xTADD2Fey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDfs9MKTB4NT"
      },
      "source": [
        "# Gridsearch LGBM mit FLAML:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q53vUc5TB4NU"
      },
      "source": [
        "CountVectorizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCNF9IALB4NU"
      },
      "outputs": [],
      "source": [
        "# Konvertieren Sie die Textdokumente in numerische Merkmale mit dem CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df_train_lyrics)\n",
        "\n",
        "# Teilen Sie die Daten in Trainings- und Testdaten auf\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df_train_labels, test_size=0.15, random_state=42)\n",
        "\n",
        "# Das Flaml-Modell deklarieren und trainieren\n",
        "automl = AutoML()\n",
        "automl.fit(X_train, y_train, task=\"classification\", metric='accuracy', estimator_list=[\"lgbm\"], time_budget=3600)\n",
        "\n",
        "# Die besten Hyperparameter ausgeben\n",
        "print('Best hyperparmeter config:', automl.best_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE1R6DEQB4NU"
      },
      "source": [
        "TfidfVectorizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czTgM0s8B4NU"
      },
      "outputs": [],
      "source": [
        "# Konvertieren Sie die Textdokumente in numerische Merkmale mit dem CountVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df_train_lyrics)\n",
        "\n",
        "# Teilen Sie die Daten in Trainings- und Testdaten auf\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df_train_labels, test_size=0.15, random_state=42)\n",
        "\n",
        "# Das Flaml-Modell deklarieren und trainieren\n",
        "automl = AutoML()\n",
        "automl.fit(X_train, y_train, task=\"classification\", metric='accuracy', estimator_list=[\"lgbm\"], time_budget=6000)\n",
        "\n",
        "# Die besten Hyperparameter ausgeben\n",
        "print('Best hyperparmeter config:', automl.best_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTjuXUEWB4NU"
      },
      "source": [
        "Spacy-Vektoren:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y00uqUnJB4NU"
      },
      "outputs": [],
      "source": [
        "# # Funktion definieren, um die Liedtexte in Vektoren zu konvertieren\n",
        "# def document_vector(text):\n",
        "#     doc = nlp(text)\n",
        "#     vectors = []\n",
        "#     for token in doc:\n",
        "#         if token.has_vector:\n",
        "#             vectors.append(token.vector)\n",
        "#     if len(vectors) > 0:\n",
        "#         return np.mean(vectors, axis=0)\n",
        "#     else:\n",
        "#         raise ValueError(\"Keine Vektoren gefunden\")\n",
        "\n",
        "# # Herausfinden, in welchen Spalten keine Vektoren vorhanden sind\n",
        "# no_vector_docs = []\n",
        "# for i, text in enumerate(df_train_lyrics):\n",
        "#     try:\n",
        "#         vec = document_vector(text)\n",
        "#     except ValueError as e:\n",
        "#         print(f\"Fehler: {e} bei Dokument {i}\")\n",
        "#         no_vector_docs.append(i)\n",
        "# print(f\"Dokumente ohne Vektoren: {no_vector_docs}\")\n",
        "\n",
        "# # Alle Zeilen ohne Vektoren löschen\n",
        "# for i in no_vector_docs:\n",
        "#   df_train_labels = df_train_labels.drop(i)\n",
        "#   del df_train_lyrics[i]\n",
        "\n",
        "# # Das Dataframe für die Labels reindexen\n",
        "# df_train_labels = df_train_labels.reset_index(drop=True)  \n",
        "\n",
        "# # Compute the document vectors\n",
        "# documents_with_vectors = []\n",
        "# labels_with_vectors = []\n",
        "# for i in range(len(df_train_lyrics)):\n",
        "#     text = df_train_lyricss[i]\n",
        "#     df_train_labels = df_train_labels[i]\n",
        "#     try:\n",
        "#         vec = document_vector(text)\n",
        "#         documents_with_vectors.append(text)\n",
        "#         labels_with_vectors.append(label)\n",
        "#     except ValueError as e:\n",
        "#         print(f\"Fehler: {e}\")\n",
        "\n",
        "# # Compute the document vectors\n",
        "# X = [document_vector(text) for text in documents_with_vectors]\n",
        "\n",
        "# # Teilen Sie die Daten in Trainings- und Testdaten auf\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, labels_with_vectors, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Das Flaml-Modell deklarieren und trainieren\n",
        "# automl = AutoML()\n",
        "# automl.fit(np.array(X_train), np.array(y_train), task=\"classification\", metric='accuracy', estimator_list=[\"lgbm\"], time_budget=6000)\n",
        "\n",
        "\n",
        "# # Die besten Hyperparameter ausgeben\n",
        "# print('Best hyperparmeter config:', automl.best_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLA ohne Hyperparameter"
      ],
      "metadata": {
        "id": "Nsx6d5Cl6lsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer:"
      ],
      "metadata": {
        "id": "FDxfDDTD6lsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vektorizer initialisiereen\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Variablen für MLA deklarieren und teils konvertieren\n",
        "X_train = vectorizer.fit_transform(df_train_lyrics)\n",
        "X_test = vectorizer.transform(df_test_lyrics)\n",
        "\n",
        "y_train = df_train_labels\n",
        "y_test = df_test_labels\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)"
      ],
      "metadata": {
        "id": "So6mdCTn6lsg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Erstellen Sie das SVM- und LGBM-Modell\n",
        "lgbm = lgb.LGBMClassifier()\n",
        "svm = SVC()\n",
        "\n",
        "# Trainieren Sie die Modelle anhand der Trainingsdaten\n",
        "lgbm.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage der Testdaten svm\n",
        "predictions_lgbm = lgbm.predict(X_test)\n",
        "predictions_svm = svm.predict(X_test)\n",
        "\n",
        "# Berechnen Sie die Genauigkeit\n",
        "accuracy_lgbm = accuracy_score(y_test, predictions_lgbm)\n",
        "accuracy_svm = accuracy_score(y_test, predictions_svm)\n",
        "\n",
        "# Den Klassifikations-Report ausgeben\n",
        "print('LGBM:')\n",
        "print(classification_report(y_test, predictions_lgbm))\n",
        "print('SVM:')\n",
        "print(classification_report(y_test, predictions_svm))\n",
        "\n",
        "# Die Genauigkeit ausgeben\n",
        "print('Accuracy LGBM CouVec:', accuracy_lgbm)\n",
        "print('Accuracy SVM CouVec:', accuracy_svm)"
      ],
      "metadata": {
        "id": "wdbDjq8G6lsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorizer:"
      ],
      "metadata": {
        "id": "CKicsJQq6lsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vektorizer initialisiereen\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Variablen für MLA deklarieren und teils konvertieren\n",
        "X_train = vectorizer.fit_transform(df_train_lyrics)\n",
        "X_test = vectorizer.transform(df_test_lyrics)\n",
        "\n",
        "y_train = df_train_labels\n",
        "y_test = df_test_labels\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)"
      ],
      "metadata": {
        "id": "Dba9oshM6lsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Erstellen Sie das SVM- und LGBM-Modell\n",
        "lgbm = lgb.LGBMClassifier()\n",
        "svm = SVC()\n",
        "\n",
        "# Trainieren Sie die Modelle anhand der Trainingsdaten\n",
        "lgbm.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage der Testdaten svm\n",
        "predictions_lgbm = lgbm.predict(X_test)\n",
        "predictions_svm = svm.predict(X_test)\n",
        "\n",
        "# Berechnen Sie die Genauigkeit\n",
        "accuracy_lgbm = accuracy_score(y_test, predictions_lgbm)\n",
        "accuracy_svm = accuracy_score(y_test, predictions_svm)\n",
        "\n",
        "# Den Klassifikations-Report ausgeben\n",
        "print('LGBM:')\n",
        "print(classification_report(y_test, predictions_lgbm))\n",
        "print('SVM:')\n",
        "print(classification_report(y_test, predictions_svm))\n",
        "\n",
        "# Die Genauigkeit ausgeben\n",
        "print('Accuracy LGBM CouVec:', accuracy_lgbm)\n",
        "print('Accuracy SVM CouVec:', accuracy_svm)"
      ],
      "metadata": {
        "id": "uwVlA2UF6lsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLA mit Hyperparameter"
      ],
      "metadata": {
        "id": "qfXodprPmZkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer:"
      ],
      "metadata": {
        "id": "vVj8EqhDmZky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vektorizer initialisiereen\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Variablen für MLA deklarieren und teils konvertieren\n",
        "X_train = vectorizer.fit_transform(df_train_lyrics)\n",
        "X_test = vectorizer.transform(df_test_lyrics)\n",
        "\n",
        "y_train = df_train_labels\n",
        "y_test = df_test_labels\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)"
      ],
      "metadata": {
        "id": "0MCVfGnQmZky"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Erstellen Sie das SVM- und LGBM-Modell\n",
        "lgbm = lgb.LGBMClassifier(n_estimators=200, num_leaves= 184, min_child_samples=3, \n",
        "                          learning_rate=0.08838576141784195, log_max_bin=9, \n",
        "                          colsample_bytree=0.39039795455449644, \n",
        "                          reg_alpha=0.014844095616079196, \n",
        "                          reg_lambda=0.05525097930389173)\n",
        "svm = SVC(C=0.01, gamma=0.07, kernel='linear')\n",
        "\n",
        "# Trainieren Sie die Modelle anhand der Trainingsdaten\n",
        "lgbm.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage der Testdaten svm\n",
        "predictions_lgbm = lgbm.predict(X_test)\n",
        "predictions_svm = svm.predict(X_test)\n",
        "\n",
        "# Berechnen Sie die Genauigkeit\n",
        "accuracy_lgbm = accuracy_score(y_test, predictions_lgbm)\n",
        "accuracy_svm = accuracy_score(y_test, predictions_svm)\n",
        "\n",
        "# Den Klassifikations-Report ausgeben\n",
        "print('LGBM:')\n",
        "print(classification_report(y_test, predictions_lgbm))\n",
        "print('SVM:')\n",
        "print(classification_report(y_test, predictions_svm))\n",
        "\n",
        "# Die Genauigkeit ausgeben\n",
        "print('Accuracy LGBM CouVec:', accuracy_lgbm)\n",
        "print('Accuracy SVM CouVec:', accuracy_svm)"
      ],
      "metadata": {
        "id": "bxuqlPugmZkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorizer:"
      ],
      "metadata": {
        "id": "37dSSbhnmZk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vektorizer initialisiereen\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Variablen für MLA deklarieren und teils konvertieren\n",
        "X_train = vectorizer.fit_transform(df_train_lyrics)\n",
        "X_test = vectorizer.transform(df_test_lyrics)\n",
        "\n",
        "y_train = df_train_labels\n",
        "y_test = df_test_labels\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)"
      ],
      "metadata": {
        "id": "nWp6e2wkmZk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Erstellen Sie das SVM- und LGBM-Modell\n",
        "lgbm = lgb.LGBMClassifier(n_estimators=67, num_leaves= 184, min_child_samples=12, \n",
        "                          learning_rate=0.085537978248575, log_max_bin=9, \n",
        "                          colsample_bytree=0.7663773657187746, \n",
        "                          reg_alpha=0.006958608037974516, \n",
        "                          reg_lambda=0.4683303882185501)\n",
        "svm = SVC(C=4.5, gamma=0.95, kernel='rbf')\n",
        "\n",
        "# Trainieren Sie die Modelle anhand der Trainingsdaten\n",
        "lgbm.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage der Testdaten svm\n",
        "predictions_lgbm = lgbm.predict(X_test)\n",
        "predictions_svm = svm.predict(X_test)\n",
        "\n",
        "# Berechnen Sie die Genauigkeit\n",
        "accuracy_lgbm = accuracy_score(y_test, predictions_lgbm)\n",
        "accuracy_svm = accuracy_score(y_test, predictions_svm)\n",
        "\n",
        "# Den Klassifikations-Report ausgeben\n",
        "print('LGBM:')\n",
        "print(classification_report(y_test, predictions_lgbm))\n",
        "print('SVM:')\n",
        "print(classification_report(y_test, predictions_svm))\n",
        "\n",
        "# Die Genauigkeit ausgeben\n",
        "print('Accuracy LGBM CouVec:', accuracy_lgbm)\n",
        "print('Accuracy SVM CouVec:', accuracy_svm)"
      ],
      "metadata": {
        "id": "DBh8eQiemZk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy-Vectorizer, leider nicht funktionsfähig"
      ],
      "metadata": {
        "id": "oC4Qy6-dpOTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ob diese Funktion funktionsfähig ist, wurde nicht getestet. Bei der Gird-SearchCV\n",
        "# und Flaml ist die Funktion so, wie sie mal eines Abends funktioniert hat aber das \n",
        "# Programm nach 6h Laufzeit abgestützt ist.\n",
        "\n",
        "def spacy_vectorizer(dataframe_lyrics, dataframe_label):\n",
        "  '''\n",
        "  input:\n",
        "    dataframe_lyrics: dataframe mit den Liedtexten\n",
        "    dataframe_label : dataframe mit den Genre\n",
        "\n",
        "  output:\n",
        "    result = array mit dem Liedtexte-Dataframe vektoisiert und mit den Genre\n",
        "  '''\n",
        "  # Funktion definieren, um die Liedtexte in Vektoren zu konvertieren\n",
        "  def document_vector(text):\n",
        "      doc = nlp(text)\n",
        "      vectors = []\n",
        "      for token in doc:\n",
        "          if token.has_vector:\n",
        "              vectors.append(token.vector)\n",
        "      if len(vectors) > 0:\n",
        "          return np.mean(vectors, axis=0)\n",
        "      else:\n",
        "          raise ValueError(\"Keine Vektoren gefunden\")\n",
        "\n",
        "  # Herausfinden, in welchen Spalten keine Vektoren vorhanden sind\n",
        "  no_vector_docs = []\n",
        "  for i, text in enumerate(dataframe_lyrics):\n",
        "      try:\n",
        "          vec = document_vector(text)\n",
        "      except ValueError as e:\n",
        "          print(f\"Fehler: {e} bei Dokument {i}\")\n",
        "          no_vector_docs.append(i)\n",
        "  print(f\"Dokumente ohne Vektoren: {no_vector_docs}\")\n",
        "\n",
        "  # Alle Zeilen ohne Vektoren löschen\n",
        "  for i in no_vector_docs:\n",
        "    dataframe_lyrics = dataframe_lyrics.drop(i)\n",
        "    dataframe_label = dataframe_label.drop(i)\n",
        "\n",
        "  # Das Dataframe für die Labels reindexen\n",
        "  dataframe_label = dataframe_label.reset_index(drop=True)  \n",
        "\n",
        "  # Compute the document vectors\n",
        "  documents_with_vectors = []\n",
        "  labels_with_vectors = []\n",
        "  for i in range(len(dataframe_lyrics)):\n",
        "      text = dataframe_lyrics[i]\n",
        "      dataframe_label = dataframe_label[i]\n",
        "      try:\n",
        "          vec = document_vector(text)\n",
        "          documents_with_vectors.append(text)\n",
        "          labels_with_vectors.append(dataframe_label)\n",
        "      except ValueError as e:\n",
        "          print(f\"Fehler: {e}\")\n",
        "\n",
        "  X = [document_vector(text) for text in documents_with_vectors]\n",
        "  y = labels_with_vectors\n",
        "  result = [X,y]"
      ],
      "metadata": {
        "id": "wYiMTV1DbNU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Laden Sie die Textdokumente und die Klassenlabels\n",
        "df_train_lyrics = df['cleaned_lyrics'] # Liste von Textdokumenten\n",
        "df_train_labels = df['Genre'] # Liste von Klassenlabels (eins pro Dokument)"
      ],
      "metadata": {
        "id": "q1SNWRx-o_aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = spacy_vectorizer(df_test_lyrics, df_test_labels)\n",
        "X_test = X[0]\n",
        "y_test = X[1]\n",
        "X_test = X_test.astype(np.float32)"
      ],
      "metadata": {
        "id": "8FTDMprulAB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = spacy_vectorizer(df_train_lyrics, df_train_labels)\n",
        "X_train = X[0]\n",
        "y_train = X[1]\n",
        "X_train = X_train.astype(np.float32)"
      ],
      "metadata": {
        "id": "4eeBT40wpE6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Erstellen Sie das SVM- und LGBM-Modell\n",
        "lgbm = lgb.LGBMClassifier()\n",
        "svm = SVC()\n",
        "\n",
        "# Trainieren Sie die Modelle anhand der Trainingsdaten\n",
        "lgbm.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage der Testdaten svm\n",
        "predictions_lgbm = lgbm.predict(X_test)\n",
        "predictions_svm = svm.predict(X_test)\n",
        "\n",
        "# Berechnen Sie die Genauigkeit\n",
        "accuracy_lgbm = accuracy_score(y_test, predictions_lgbm)\n",
        "accuracy_svm = accuracy_score(y_test, predictions_svm)\n",
        "\n",
        "# Den Klassifikations-Report ausgeben\n",
        "print('LGBM:')\n",
        "print(classification_report(y_test, predictions_lgbm))\n",
        "print('SVM:')\n",
        "print(classification_report(y_test, predictions_svm))\n",
        "\n",
        "# Die Genauigkeit ausgeben\n",
        "print('Accuracy LGBM CouVec:', accuracy_lgbm)\n",
        "print('Accuracy SVM CouVec:', accuracy_svm)"
      ],
      "metadata": {
        "id": "vZzCwqgApM6Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "fyb6mPpCJADk",
        "rRr671g-UD2w",
        "_hbI7RZuVHsq",
        "cRpm6PPNA00O",
        "hhYo2eIkBcec",
        "QDfs9MKTB4NT",
        "Nsx6d5Cl6lsf",
        "qfXodprPmZkx",
        "oC4Qy6-dpOTh"
      ],
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}